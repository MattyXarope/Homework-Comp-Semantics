{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment 2 - Code.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "X1kiZfEVK8Th",
        "4Bvpxa_PLLNM"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MattyXarope/Homework-Comp-Semantics/blob/main/Assignment_2_Code.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KEnSJ30oLXat"
      },
      "source": [
        "# Import Packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KGPxhD8PCrHm",
        "outputId": "88fa35e7-7c3c-42a2-d9f9-eb89f5fc88ce"
      },
      "source": [
        "# -*- coding: utf-8 -*- \n",
        "import nltk\n",
        "import re\n",
        "nltk.download('wordnet')\n",
        "nltk.download('word2vec_sample')\n",
        "import numpy as np\n",
        "from nltk.corpus import wordnet \n",
        "import pandas as pd\n",
        "from nltk.corpus import brown\n",
        "from nltk.tokenize import sent_tokenize\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.text import Text\n",
        "import re\n",
        "import csv \n",
        "from itertools import chain\n",
        "import gensim\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "path_to_word2vec_sample = nltk.data.find('models/word2vec_sample/pruned.word2vec.txt')\n",
        "word2vec_gensim = gensim.models.KeyedVectors.load_word2vec_format(path_to_word2vec_sample)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n",
            "[nltk_data] Downloading package word2vec_sample to /root/nltk_data...\n",
            "[nltk_data]   Unzipping models/word2vec_sample.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X1kiZfEVK8Th"
      },
      "source": [
        "# Exercise 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "grcHEvqOC0Mq",
        "outputId": "ca679914-046a-44d9-936d-ef3a04b3f2e1"
      },
      "source": [
        "## Exercise 1 ##\n",
        "\n",
        "#Tests to see how many senses there are for the word language \n",
        "word = 'language'\n",
        "synsets = wordnet.synsets(word, lang=\"eng\")\n",
        "n_synsets = len(synsets)\n",
        "\n",
        "#Prints information about synsets for the word \n",
        "print(f'Lemma English: {word}')\n",
        "print(f'Number of synsets: {n_synsets}')\n",
        "print(f'Synsets details: ')\n",
        "for ss in synsets:\n",
        "    print(f'Name: {ss.name()}')\n",
        "    print(f'Gloss: {ss.definition()}')\n",
        "    print(f'Lemmas English: {ss.lemmas()}')\n",
        "    print(f'\\n')\n",
        "    \n",
        "#Establishes a concordance list for the word language in the Brown corpus (commented out due to use of sketch engine)\n",
        "# corpus = brown.words()\n",
        "# text = Text(corpus)\n",
        "# con_list = text.concordance_list(\"language\", width=250, lines=100)\n",
        "# df = pd.DataFrame(data={\"Utterance\": con_list})\n",
        "# df.to_csv(\"./Brown100.csv\", sep=',',index=False)\n",
        "\n",
        "#Adds file from SketchEngine of 100 instances of 'language' in the Brown corpus \n",
        "\n",
        "CSV_BROWN = \"https://raw.githubusercontent.com/MattyXarope/Homework-Comp-Semantics/main/Brown100Final.csv\"\n",
        "lang_syn = pd.read_csv(CSV_BROWN)\n",
        "\n",
        "#Create contigency table using data from lang_syn\n",
        "adelle = lang_syn['adelle']\n",
        "matt = lang_syn['matt']\n",
        "annotations = pd.DataFrame({'Adelle': adelle, 'Matt': matt})\n",
        "\n",
        "#Print contigency table data\n",
        "print(f'******************\\n')\n",
        "print('contingency table: ')\n",
        "print(f'******************\\n\\n')\n",
        "# note the 'margins=True' parameter -- make sure you understand what it does\n",
        "print(pd.crosstab(annotations['Adelle'], annotations['Matt'], margins=True))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Lemma English: language\n",
            "Number of synsets: 6\n",
            "Synsets details: \n",
            "Name: language.n.01\n",
            "Gloss: a systematic means of communicating by the use of sounds or conventional symbols\n",
            "Lemmas English: [Lemma('language.n.01.language'), Lemma('language.n.01.linguistic_communication')]\n",
            "\n",
            "\n",
            "Name: speech.n.02\n",
            "Gloss: (language) communication by word of mouth\n",
            "Lemmas English: [Lemma('speech.n.02.speech'), Lemma('speech.n.02.speech_communication'), Lemma('speech.n.02.spoken_communication'), Lemma('speech.n.02.spoken_language'), Lemma('speech.n.02.language'), Lemma('speech.n.02.voice_communication'), Lemma('speech.n.02.oral_communication')]\n",
            "\n",
            "\n",
            "Name: lyric.n.01\n",
            "Gloss: the text of a popular song or musical-comedy number\n",
            "Lemmas English: [Lemma('lyric.n.01.lyric'), Lemma('lyric.n.01.words'), Lemma('lyric.n.01.language')]\n",
            "\n",
            "\n",
            "Name: linguistic_process.n.02\n",
            "Gloss: the cognitive processes involved in producing and understanding linguistic communication\n",
            "Lemmas English: [Lemma('linguistic_process.n.02.linguistic_process'), Lemma('linguistic_process.n.02.language')]\n",
            "\n",
            "\n",
            "Name: language.n.05\n",
            "Gloss: the mental faculty or power of vocal communication\n",
            "Lemmas English: [Lemma('language.n.05.language'), Lemma('language.n.05.speech')]\n",
            "\n",
            "\n",
            "Name: terminology.n.01\n",
            "Gloss: a system of words used to name things in a particular discipline\n",
            "Lemmas English: [Lemma('terminology.n.01.terminology'), Lemma('terminology.n.01.nomenclature'), Lemma('terminology.n.01.language')]\n",
            "\n",
            "\n",
            "******************\n",
            "\n",
            "contingency table: \n",
            "******************\n",
            "\n",
            "\n",
            "Matt    s1  s2  s3  s4  s5  s6  All\n",
            "Adelle                             \n",
            "s1      53  10   0   3   0   4   70\n",
            "s2       7   1   0   0   0   0    8\n",
            "s3       0   0   1   0   0   0    1\n",
            "s4       4   0   0   0   0   0    4\n",
            "s5       2   0   0   0   1   1    4\n",
            "s6       0   5   0   0   0   8   13\n",
            "All     66  16   1   3   1  13  100\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Bvpxa_PLLNM"
      },
      "source": [
        "# Exercise 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZhuJT2dCDJFp",
        "outputId": "6c6a0ec9-879f-4d60-a2d8-5225d2c7b270"
      },
      "source": [
        "## Exercise 2 ## \n",
        "\n",
        "#S1 Info\n",
        "#Gloss: a systematic means of communicating by the use of sounds or conventional symbols\n",
        "#Percent of all utterances \n",
        "all_percentS1 = (53/100)*100\n",
        "print(f'S1 was agreed upon by both annotators in {all_percentS1}% of all utterances')\n",
        "\n",
        "#S2 Info\n",
        "#Gloss: (language) communication by word of mouth\n",
        "#Percent of all utterances \n",
        "all_percentS2 = (1/100)*100\n",
        "print(f'S2 was agreed upon by both annotators in {all_percentS2}% of all utterances')\n",
        "\n",
        "#S3 Info\n",
        "#Gloss: the text of a popular song or musical-comedy number\n",
        "#Percent of all utterances \n",
        "all_percentS3 = (1/100)*100\n",
        "print(f'S3 was agreed upon by both annotators in {all_percentS3}% of all utterances')\n",
        "\n",
        "#S4 Info\n",
        "#Gloss: the cognitive processes involved in producing and understanding linguistic communication\n",
        "#Percent of all utterances \n",
        "all_percentS4 = (0/100)*100\n",
        "print(f'S4 was agreed upon by both annotators in {all_percentS4}% of all utterances')\n",
        "\n",
        "#S5 Info\n",
        "#Gloss: the mental faculty or power of vocal communication\n",
        "#Percent of all utterances \n",
        "all_percentS5 = (1/100)*100\n",
        "print(f'S5 was agreed upon by both annotators in {all_percentS5}% of all utterances')\n",
        "\n",
        "#S6 Info\n",
        "#Gloss: a system of words used to name things in a particular discipline\n",
        "#Percent of all utterances \n",
        "all_percentS6 = (8/100)*100\n",
        "print(f'S6 was agreed upon by both annotators in {all_percentS6}% of all utterances')\n",
        "\n",
        "#Print General Info for this section\n",
        "all_agreements = all_percentS1 + all_percentS2 + all_percentS3 + all_percentS4 + all_percentS5 + all_percentS6\n",
        "print(f'The annotators agreed on {all_agreements}% of all utterances')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "S1 was agreed upon by both annotators in 53.0% of all utterances\n",
            "S2 was agreed upon by both annotators in 1.0% of all utterances\n",
            "S3 was agreed upon by both annotators in 1.0% of all utterances\n",
            "S4 was agreed upon by both annotators in 0.0% of all utterances\n",
            "S5 was agreed upon by both annotators in 1.0% of all utterances\n",
            "S6 was agreed upon by both annotators in 8.0% of all utterances\n",
            "The annotators agreed on 64.0% of all utterances\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bc89QxxkLQzV"
      },
      "source": [
        "# Exercise 3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BTwY0cc9DaY5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5ef24434-7395-48d5-ef65-b48762d89aa8"
      },
      "source": [
        "## Exercise 3 ## \n",
        "lemmas=[]\n",
        "synonyms=[]\n",
        "antonyms=[]\n",
        "\n",
        "#For loop to add synonyms from wordnet to list \n",
        "\n",
        "for word in wordnet.words(): \n",
        "#    print (word,end=\": \") \n",
        "    for syn in wordnet.synsets(word)[5:]: \n",
        "      for l in syn.lemmas():\n",
        "        if len(wordnet.synsets(word)) > 0 and len(l.antonyms()) > 0: \n",
        "          lemmas.append(word) \n",
        "          synonyms.append(wordnet.synsets(word)[0].lemma_names()[0])\n",
        "          if l.antonyms():\n",
        "            antonyms.append(l.antonyms()[0].name())\n",
        "    if len(synonyms) > 500: \n",
        "        break  \n",
        "\n",
        "#Fucntion to compare the cosine similarites in word2vec \n",
        "  \n",
        "\n",
        "def cosine_gensim(list1, list2):\n",
        "  similarities = []\n",
        "  for elem1,elem2 in zip(list1,list2):\n",
        "    if elem1 in word2vec_gensim and elem2 in word2vec_gensim:\n",
        "      similarities.append(word2vec_gensim.similarity(elem1, elem2))  \n",
        "  return similarities\n",
        "\n",
        "print(len(cosine_gensim(lemmas, synonyms)))\n",
        "print(len(cosine_gensim(lemmas, antonyms)))\n"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "448\n",
            "351\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s7RCPqurkd8p",
        "outputId": "79defa46-0d0d-43af-d6e4-40d63b3b7566"
      },
      "source": [
        "#Prints info about syns/antoyms\n",
        "print(len(lemmas))\n",
        "print(len(synonyms))\n",
        "print(len(antonyms))\n",
        "\n",
        "print(lemmas)\n",
        "print(synonyms)\n",
        "print(antonyms)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "502\n",
            "502\n",
            "502\n",
            "['absorbed', 'absorbing', 'abstract', 'abused', 'accommodating', 'accommodating', 'accompanied', 'acknowledged', 'active', 'active', 'active', 'active', 'active', 'active', 'active', 'active', 'active', 'active', 'addressed', 'adjusted', 'adjusted', 'adopted', 'advance', 'advance', 'advance', 'advance', 'advance', 'advanced', 'advanced', 'advanced', 'advancing', 'advancing', 'advancing', 'affected', 'affected', 'affected', 'agitated', 'agitated', 'altered', 'alternate', 'alternating', 'animate', 'animate', 'appealing', 'appealing', 'applied', 'applied', 'arranged', 'articulate', 'articulate', 'articulated', 'ascending', 'ascending', 'assigned', 'associate', 'attached', 'attached', 'attended', 'back', 'back', 'back', 'back', 'back', 'back', 'back', 'backed', 'backed', 'backed', 'backward', 'backward', 'bad', 'bare', 'bare', 'bared', 'bearing', 'bedded', 'bedded', 'beginning', 'beginning', 'beginning', 'bent', 'best', 'best', 'best', 'best', 'best', 'best', 'best', 'best', 'better', 'better', 'better', 'better', 'better', 'better', 'better', 'better', 'better', 'better', 'better', 'better', 'better', 'big', 'binding', 'binding', 'black', 'black', 'black', 'black', 'blind', 'blocked', 'blocked', 'blocked', 'blocked', 'blocked', 'blown', 'blurred', 'bordered', 'born', 'bottom', 'bound', 'bound', 'bound', 'bound', 'bound', 'bowed', 'branded', 'breathing', 'bright', 'broke', 'broke', 'broke', 'broke', 'broken', 'broken', 'broken', 'broken', 'broken', 'broken', 'broken', 'buried', 'buried', 'calm', 'calm', 'cancelled', 'cardinal', 'catching', 'center', 'certified', 'changed', 'charged', 'charged', 'charged', 'charged', 'checked', 'choked', 'choked', 'classified', 'clean', 'clean', 'clean', 'clean', 'clean', 'clear', 'clear', 'clear', 'clear', 'clear', 'clear', 'cleared', 'cleared', 'cleared', 'close', 'close', 'close', 'close', 'close', 'close', 'closed', 'closed', 'closed', 'closed', 'closed', 'closing', 'closing', 'closing', 'closing', 'closing', 'closing', 'collected', 'collected', 'color', 'color', 'colored', 'colour', 'colour', 'colour', 'coloured', 'combined', 'coming', 'committed', 'committed', 'compact', 'compact', 'complete', 'composed', 'compound', 'concentrated', 'concentrated', 'concentrated', 'conditioned', 'confined', 'confined', 'confirmed', 'confirming', 'confused', 'connected', 'connected', 'content', 'content', 'continued', 'contracted', 'contracted', 'contracted', 'controlled', 'cooked', 'cool', 'cool', 'cool', 'correct', 'correct', 'correct', 'corrected', 'corrupt', 'covered', 'critical', 'cross', 'crossed', 'crossed', 'crowned', 'crowned', 'crying', 'curved', 'curving', 'cut', 'cut', 'cut', 'cut', 'cut', 'cut', 'cut', 'cutting', 'cutting', 'dark', 'dark', 'deadened', 'deadening', 'decent', 'declared', 'dedicated', 'deep', 'defending', 'defined', 'deflated', 'delineate', 'delineated', 'demanding', 'depressing', 'derived', 'designed', 'detached', 'determined', 'developed', 'differentiated', 'dim', 'dimmed', 'direct', 'direct', 'direct', 'direct', 'direct', 'direct', 'discharged', 'discharged', 'discharged', 'distributed', 'divided', 'done', 'double', 'double', 'down', 'down', 'down', 'down', 'down', 'down', 'down', 'drawn', 'drawn', 'driven', 'driving', 'dropping', 'dropping', 'dropping', 'drunk', 'dry', 'dry', 'dry', 'dry', 'dry', 'dull', 'dull', 'dull', 'dull', 'dying', 'earlier', 'earliest', 'early', 'east', 'easy', 'empty', 'engaged', 'engaged', 'engaging', 'engaging', 'equal', 'essential', 'established', 'even', 'excited', 'exciting', 'exhausted', 'expanded', 'expanded', 'expected', 'experienced', 'expressed', 'extended', 'faced', 'failing', 'failing', 'failing', 'fair', 'fair', 'fair', 'fallen', 'falling', 'falling', 'fancy', 'fast', 'fastened', 'fastened', 'fat', 'feathered', 'federal', 'fell', 'fell', 'fell', 'filled', 'fine', 'finer', 'finished', 'finished', 'first', 'first', 'fit', 'fit', 'fit', 'fitted', 'fitting', 'fixed', 'flat', 'flat', 'flat', 'focused', 'focussed', 'folding', 'following', 'following', 'forced', 'formed', 'forward', 'forward', 'forward', 'forward', 'forward', 'foul', 'found', 'found', 'framed', 'free', 'free', 'free', 'free', 'free', 'free', 'free', 'fresh', 'fretted', 'front', 'front', 'front', 'frozen', 'frozen', 'frozen', 'full', 'funded', 'gathered', 'gathered', 'general', 'given', 'giving', 'giving', 'glassed', 'glazed', 'glazed', 'go', 'go', 'go', 'go', 'go', 'going', 'going', 'going', 'going', 'gone', 'gone', 'gone', 'good', 'good', 'green', 'guided', 'handled', 'handless', 'hard', 'hard', 'hard', 'hard', 'hardened', 'hardened', 'headed', 'headed', 'hearing', 'heavy', 'heavy', 'heavy', 'held', 'here', 'high', 'high', 'high', 'higher', 'hollow', 'home', 'hurt', 'ill', 'ill', 'inactive', 'inactive', 'inactive', 'inactive', 'inclined', 'inclined', 'inclined', 'induced', 'inferior', 'infernal', 'inside', 'inside', 'inside', 'inside', 'inspired', 'inspiring', 'inspiring', 'insured', 'integrated', 'integrated', 'inviting', 'involved', 'irregular', 'jade', 'jammed', 'joint', 'kept', 'keyed', 'known', 'labeled', 'labelled', 'laced', 'landed', 'lashing', 'last', 'late', 'late', 'later', 'later', 'latest', 'latest', 'lay', 'lay', 'leaded', 'leaded']\n",
            "['absorb', 'absorb', 'abstraction', 'mistreat', 'suit', 'suit', 'attach_to', 'admit', 'active_agent', 'active_agent', 'active_agent', 'active_agent', 'active_agent', 'active_agent', 'active_agent', 'active_agent', 'active_agent', 'active_agent', 'address', 'adjust', 'adjust', 'adopt', 'progress', 'progress', 'progress', 'progress', 'progress', 'advance', 'advance', 'advance', 'advance', 'advance', 'advance', 'affect', 'affect', 'affect', 'agitate', 'agitate', 'change', 'surrogate', 'alternate', 'inspire', 'inspire', 'appeal', 'appeal', 'use', 'use', 'arrange', 'joint', 'joint', 'joint', 'rise', 'rise', 'delegate', 'associate', 'attach', 'attach', 'attend', 'back', 'back', 'back', 'back', 'back', 'back', 'back', 'back', 'back', 'back', 'backward', 'backward', 'bad', 'bare', 'bare', 'bare', 'bearing', 'bed', 'bed', 'beginning', 'beginning', 'beginning', 'bent', 'best', 'best', 'best', 'best', 'best', 'best', 'best', 'best', 'better', 'better', 'better', 'better', 'better', 'better', 'better', 'better', 'better', 'better', 'better', 'better', 'better', 'large', 'binding', 'binding', 'black', 'black', 'black', 'black', 'blind', 'barricade', 'barricade', 'barricade', 'barricade', 'barricade', 'blow', 'film_over', 'surround', 'Born', 'bottom', 'boundary', 'boundary', 'boundary', 'boundary', 'boundary', 'bow', 'brand', 'breathing', 'bright', 'interrupt', 'interrupt', 'interrupt', 'interrupt', 'interrupt', 'interrupt', 'interrupt', 'interrupt', 'interrupt', 'interrupt', 'interrupt', 'bury', 'bury', 'composure', 'composure', 'cancel', 'cardinal', 'catching', 'center', 'attest', 'change', 'charge', 'charge', 'charge', 'charge', 'check', 'choke', 'choke', 'classified_ad', 'clean_and_jerk', 'clean_and_jerk', 'clean_and_jerk', 'clean_and_jerk', 'clean_and_jerk', 'clear', 'clear', 'clear', 'clear', 'clear', 'clear', 'unclutter', 'unclutter', 'unclutter', 'stopping_point', 'stopping_point', 'stopping_point', 'stopping_point', 'stopping_point', 'stopping_point', 'close', 'close', 'close', 'close', 'close', 'shutting', 'shutting', 'shutting', 'shutting', 'shutting', 'shutting', 'roll_up', 'roll_up', 'color', 'color', 'colored_person', 'coloring_material', 'coloring_material', 'coloring_material', 'color', 'unite', 'approach', 'perpetrate', 'perpetrate', 'compact', 'compact', 'complete', 'compose', 'compound', 'concentrate', 'concentrate', 'concentrate', 'condition', 'restrict', 'restrict', 'confirm', 'confirm', 'confuse', 'connect', 'connect', 'content', 'content', 'continue', 'contract', 'contract', 'contract', 'control', 'cook', 'cool', 'cool', 'cool', 'correct', 'correct', 'correct', 'correct', 'corrupt', 'cover', 'critical', 'cross', 'traverse', 'traverse', 'crown', 'crown', 'crying', 'swerve', 'swerve', 'cut', 'cut', 'cut', 'cut', 'cut', 'cut', 'cut', 'film_editing', 'film_editing', 'dark', 'dark', 'dampen', 'stultification', 'decent', 'declare', 'give', 'deep', 'defend', 'specify', 'deflate', 'define', 'define', 'demand', 'depress', 'deduce', 'plan', 'detach', 'determine', 'develop', 'distinguish', 'dim', 'dim', 'direct', 'direct', 'direct', 'direct', 'direct', 'direct', 'dispatch', 'dispatch', 'dispatch', 'distribute', 'divide', 'make', 'double', 'double', 'down', 'down', 'down', 'down', 'down', 'down', 'down', 'pull', 'pull', 'drive', 'drive', 'drop', 'drop', 'drop', 'drunkard', 'dry', 'dry', 'dry', 'dry', 'dry', 'dull', 'dull', 'dull', 'dull', 'death', 'earlier', 'earlier', 'early', 'east', 'easy', 'empty', 'prosecute', 'prosecute', 'prosecute', 'prosecute', 'peer', 'necessity', 'establish', 'evening', 'excite', 'excite', 'exhaust', 'expand', 'expand', 'expect', 'experience', 'express', 'widen', 'confront', 'failing', 'failing', 'failing', 'carnival', 'carnival', 'carnival', 'fall', 'fall', 'fall', 'illusion', 'fast', 'fasten', 'fasten', 'fat', 'feather', 'Federal', 'hide', 'hide', 'hide', 'fill', 'fine', 'finer', 'complete', 'complete', 'first', 'first', 'fit', 'fit', 'fit', 'suit', 'adjustment', 'repair', 'flat', 'flat', 'flat', 'concentrate', 'concentrate', 'protein_folding', 'following', 'following', 'coerce', 'form', 'forward', 'forward', 'forward', 'forward', 'forward', 'foul', 'found', 'found', 'frame', 'free', 'free', 'free', 'free', 'free', 'free', 'free', 'fresh', 'fuss', 'front', 'front', 'front', 'freeze', 'freeze', 'freeze', 'full_moon', 'fund', 'gather', 'gather', 'general', 'given', 'giving', 'giving', 'glass', 'glaze', 'glaze', 'go', 'go', 'go', 'go', 'go', 'departure', 'departure', 'departure', 'departure', 'travel', 'travel', 'travel', 'good', 'good', 'green', 'steer', 'manage', 'handle', 'difficult', 'difficult', 'difficult', 'difficult', 'harden', 'harden', 'head', 'head', 'hearing', 'heavy', 'heavy', 'heavy', 'keep', 'here', 'high', 'high', 'high', 'higher', 'hollow', 'home', 'injury', 'ailment', 'ailment', 'inactive', 'inactive', 'inactive', 'inactive', 'tend', 'tend', 'tend', 'induce', 'inferior', 'infernal', 'inside', 'inside', 'inside', 'inside', 'inspire', 'inspire', 'inspire', 'insured', 'integrate', 'integrate', 'invite', 'involve', 'guerrilla', 'jade', 'throng', 'joint', 'keep', 'identify', 'know', 'label', 'label', 'intertwine', 'land', 'whipping', 'stopping_point', 'late', 'late', 'later', 'later', 'latest', 'latest', 'ballad', 'ballad', 'lead', 'lead']\n",
            "['emit', 'emit', 'concrete', 'unabused', 'disoblige', 'unaccommodating', 'unaccompanied', 'unacknowledged', 'passive', 'inactive', 'inactive', 'inactive', 'quiet', 'passive', 'stative', 'extinct', 'dormant', 'inactive', 'unaddressed', 'unadjusted', 'maladjusted', 'native', 'recede', 'back', 'fall_back', 'regress', 'demote', 'fall_back', 'regress', 'demote', 'fall_back', 'regress', 'demote', 'unaffected', 'unaffected', 'unmoved', 'unagitated', 'unagitated', 'unaltered', 'opposite', 'direct', 'inanimate', 'insentient', 'unappealing', 'unsympathetic', 'exempt', 'theoretical', 'disarranged', 'inarticulate', 'unarticulated', 'unarticulated', 'set', 'descending', 'unassigned', 'dissociate', 'detached', 'unattached', 'unaccompanied', 'advance', 'front', 'veer', 'front', 'forward', 'ahead', 'forward', 'front', 'veer', 'backless', 'ahead', 'forward', 'unregretful', 'sheathed', 'covered', 'unbar', 'nonbearing', 'unstratified', 'bedless', 'end', 'end', 'end', 'unbend', 'bad', 'evil', 'ill', 'ill', 'badly', 'badly', 'disadvantageously', 'badly', 'worsen', 'worsen', 'worse', 'worse', 'bad', 'evil', 'ill', 'ill', 'ill', 'badly', 'badly', 'disadvantageously', 'badly', 'small', 'unbind', 'untie', 'white', 'whiten', 'white', 'white', 'sighted', 'unstuff', 'free', 'remember', 'unfreeze', 'unblock', 'conserve', 'focus', 'unbordered', 'unborn', 'side', 'unbind', 'untie', 'unbound', 'free', 'unbound', 'plucked', 'unbranded', 'breathless', 'dimmed', 'keep', 'conform_to', 'make', 'promote', 'keep', 'conform_to', 'make', 'promote', 'unbroken', 'unbroken', 'unbroken', 'remember', 'unburied', 'stimulate', 'stormy', 'on', 'ordinal', 'unhitch', 'left', 'uncertified', 'unchanged', 'discharge', 'pay_cash', 'calm', 'uncharged', 'disagree', 'unclog', 'be_born', 'unclassified', 'dirty', 'unclean', 'dirty', 'dirty', 'unfairly', 'bounce', 'convict', 'unclear', 'opaque', 'ill-defined', 'cloudy', 'bounce', 'convict', 'uncleared', 'open', 'open', 'open', 'distant', 'distant', 'far', 'open', 'open', 'open', 'open', 'open', 'open', 'open', 'open', 'open', 'open', 'opening', 'uncollected', 'ungathered', 'discolor', 'black-and-white', 'uncolored', 'colorlessness', 'discolor', 'black-and-white', 'uncolored', 'uncombined', 'leave', 'uncommitted', 'unattached', 'decompress', 'loose', 'incomplete', 'discomposed', 'simple', 'distributed', 'soft', 'unsaturated', 'unconditioned', 'invasive', 'unconfined', 'unconfirmed', 'negative', 'clearheaded', 'unplug', 'unconnected', 'discontent', 'discontented', 'discontinued', 'widen', 'expand', 'expanded', 'uncontrolled', 'raw', 'warm', 'warm', 'warm', 'incorrect', 'wrong', 'wrong', 'uncorrected', 'straight', 'bare', 'noncritical', 'uncross', 'uncrossed', 'uncrossed', 'unlaureled', 'uncrowned', 'laugh', 'straight', 'straight', 'switch_on', 'expand', 'uncut', 'uncut', 'untrimmed', 'unmown', 'uncut', 'switch_on', 'expand', 'light', 'light', 'enliven', 'enliven', 'improperly', 'undeclared', 'desecrated', 'shallow', 'prosecute', 'undefined', 'inflate', 'undelineated', 'undelineated', 'undemanding', 'cheerful', 'underived', 'undesigned', 'attached', 'undetermined', 'undeveloped', 'undifferentiated', 'undimmed', 'undimmed', 'indirect', 'indirect', 'collateral', 'retrograde', 'inverse', 'alternating', 'convict', 'enlist', 'fill', 'concentrated', 'united', 'unmake', 'single', 'multivalent', 'up', 'up', 'upwards', 'upward', 'upwardly', 'up', 'up', 'deposit', 'repel', 'attract', 'attract', 'sharpen', 'attend_to', 'recuperate', 'sober', 'wet', 'wet', 'wet', 'sweet', 'phlegmy', 'lively', 'bright', 'sharp', 'sharp', 'nascent', 'late', 'late', 'late', 'west', 'quickly', 'full', 'disengage', 'disengage', 'disengage', 'disengage', 'inadequate', 'adjective', 'unestablished', 'uneven', 'unexcited', 'unexciting', 'unexhausted', 'contract', 'contracted', 'unexpected', 'inexperienced', 'implicit', 'unextended', 'faceless', 'manage', 'pass', 'pass', 'unfair', 'foul', 'unfairly', 'increase', 'increase', 'rising', 'plain', 'slow', 'unbuttoned', 'untied', 'nonfat', 'unfeathered', 'unitary', 'ascend', 'rise', 'increase', 'unfilled', 'coarse', 'coarse', 'unfinished', 'unfinished', 'last', 'second', 'disagree', 'unfit', 'unfit', 'disagree', 'disagree', 'unfixed', 'contrasty', 'natural', 'indirectly', 'unfocused', 'unfocused', 'open', 'precede', 'leading', 'push', 'unformed', 'reverse', 'backward', 'back', 'backward', 'aft', 'fair', 'lose', 'lost', 'unframed', 'obstruct', 'blame', 'block', 'freeze', 'unfree', 'bound', 'unfree', 'salty', 'unfretted', 'back', 'back', 'back', 'unfreeze', 'unblock', 'unfrozen', 'thin', 'unfunded', 'uncollected', 'ungathered', 'local', 'starve', 'take', 'starve', 'unglazed', 'unglazed', 'unglazed', 'come', 'malfunction', 'be_born', 'stop', 'no-go', 'come', 'malfunction', 'be_born', 'stop', 'malfunction', 'be_born', 'stop', 'evil', 'ill', 'ripe', 'unguided', 'handleless', 'handed', 'voiced', 'soft', 'soft', 'lightly', 'untempered', 'soft', 'unheaded', 'headless', 'deaf', 'light', 'light', 'light', 'disagree', 'there', 'low', 'low', 'low', 'low', 'solid', 'away', 'be_well', 'well', 'well', 'active', 'active', 'active', 'active', 'indispose', 'disinclined', 'horizontal', 'spontaneous', 'superior', 'supernal', 'outside', 'outdoors', 'outside', 'outwardly', 'exhale', 'exhale', 'uninspiring', 'uninsured', 'nonintegrated', 'segregated', 'uninviting', 'uninvolved', 'regular', 'refresh', 'free', 'separate', 'broken', 'keyless', 'unknown', 'unlabeled', 'unlabeled', 'unlaced', 'landless', 'unlash', 'first', 'early', 'early', 'early', 'early', 'early', 'early', 'sit', 'arise', 'follow', 'unleaded']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3pEZslE4W4VS"
      },
      "source": [
        "#Determines hypo/hypernyms\n",
        "\n",
        "lemmas2=[]\n",
        "hypernyms=[]\n",
        "hyponyms=[]\n",
        "\n",
        "for word in wordnet.words(): \n",
        "    for syn in wordnet.synsets(word)[5:]: \n",
        "      for l in syn.lemmas():\n",
        "        if len(syn.hypernyms()) > 0 and len(syn.hyponyms()) > 0: \n",
        "          lemmas2.append(syn.lemma_names()[0]) \n",
        "          hypernyms.append(syn.hypernyms()[0].lemma_names()[0])\n",
        "          hyponyms.append(syn.hyponyms()[0].lemma_names()[0])\n",
        "    if len(hypernyms) > 500: \n",
        "        break  "
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YBGbLTviVFLY",
        "outputId": "badd31d1-b6c1-49e8-f590-fcb68178916f"
      },
      "source": [
        "#prints info about hypo/hypernyms \n",
        "print(len(lemmas2))\n",
        "print(len(hypernyms))\n",
        "print(len(hyponyms))\n",
        "\n",
        "print(lemmas2)\n",
        "print(hypernyms)\n",
        "print(hyponyms)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "514\n",
            "514\n",
            "514\n",
            "['steep', 'steep', 'steep', 'steep', 'steep', 'steep', 'steep', 'absorb', 'absorb', 'absorb', 'absorb', 'steep', 'steep', 'steep', 'steep', 'steep', 'steep', 'steep', 'absorb', 'absorb', 'absorb', 'absorb', 'bear', 'bear', 'bear', 'bear', 'bear', 'bear', 'bear', 'bear', 'act', 'act', 'act', 'act', 'cover', 'cover', 'cover', 'cover', 'cover', 'cover', 'address', 'address', 'address', 'espouse', 'espouse', 'espouse', 'espouse', 'advance', 'advance', 'advance', 'advance', 'advance', 'advance', 'promote', 'promote', 'promote', 'promote', 'promote', 'advance', 'advance', 'progress', 'progress', 'progress', 'progress', 'progress', 'progress', 'progress', 'promote', 'promote', 'promote', 'promote', 'promote', 'promote', 'progress', 'progress', 'progress', 'progress', 'progress', 'progress', 'progress', 'promote', 'promote', 'promote', 'promote', 'promote', 'promote', 'progress', 'progress', 'progress', 'progress', 'progress', 'progress', 'progress', 'promote', 'promote', 'promote', 'promote', 'promote', 'promote', 'agitate', 'agitate', 'agitate', 'agitate', 'agitate', 'agitate', 'agitate', 'agitate', 'agitate', 'agitate', 'agitate', 'agitate', 'agitate', 'agitate', 'alternate', 'alternate', 'suffice', 'suffice', 'suffice', 'suffice', 'give', 'give', 'enforce', 'enforce', 'enforce', 'set_about', 'set_about', 'set_about', 'approach', 'approach', 'approach', 'arouse', 'arouse', 'arouse', 'arouse', 'arouse', 'arrange', 'arrange', 'arrange', 'arrange', 'arrange', 'arrange', 'assign', 'assign', 'associate', 'associate', 'associate', 'associate', 'associate', 'associate', 'associate', 'consort', 'consort', 'consort', 'consort', 'consociate', 'consociate', 'assume', 'assume', 'assume', 'assume', 'assume', 'simulate', 'simulate', 'simulate', 'simulate', 'wear', 'wear', 'wear', 'wear', 'wear', 'assume', 'assume', 'assume', 'assume', 'assume', 'simulate', 'simulate', 'simulate', 'simulate', 'wear', 'wear', 'wear', 'wear', 'wear', 'promise', 'promise', 'promise', 'promise', 'binding', 'binding', 'binding', 'binding', 'back', 'back', 'back', 'back', 'back', 'back', 'back', 'back', 'back', 'back', 'bet_on', 'bet_on', 'bet_on', 'bet_on', 'bet_on', 'bet_on', 'bet_on', 'bet_on', 'bet_on', 'bet_on', 'bet_on', 'bet_on', 'sleep_together', 'sleep_together', 'sleep_together', 'sleep_together', 'sleep_together', 'sleep_together', 'sleep_together', 'sleep_together', 'sleep_together', 'sleep_together', 'sleep_together', 'sleep_together', 'sleep_together', 'sleep_together', 'sleep_together', 'sleep_together', 'sleep_together', 'sleep_together', 'sleep_together', 'sleep_together', 'sleep_together', 'sleep_together', 'sleep_together', 'sleep_together', 'sleep_together', 'banish', 'banish', 'banish', 'floor', 'floor', 'basis', 'basis', 'basis', 'basis', 'basis', 'basis', 'base', 'base', 'base', 'nucleotide', 'nucleotide', 'base', 'base', 'bass', 'bass', 'bass', 'bass', 'bass', 'bat', 'alcove', 'alcove', 'bearing', 'bear', 'give_birth', 'give_birth', 'give_birth', 'give_birth', 'give_birth', 'digest', 'digest', 'digest', 'digest', 'digest', 'digest', 'digest', 'digest', 'digest', 'digest', 'digest', 'digest', 'bear', 'bear', 'bear', 'bear', 'bear', 'bear', 'bear', 'hold', 'hold', 'hold', 'hold', 'yield', 'yield', 'yield', 'behave', 'behave', 'behave', 'behave', 'behave', 'behave', 'behave', 'meter', 'meter', 'meter', 'meter', 'meter', 'beat', 'beat', 'beat', 'beat', 'beat', 'beat', 'beat', 'beat', 'beat', 'beat', 'beat', 'beat', 'beat', 'beat', 'beat', 'beat', 'beat', 'perplex', 'perplex', 'perplex', 'perplex', 'perplex', 'perplex', 'perplex', 'perplex', 'perplex', 'perplex', 'perplex', 'perplex', 'perplex', 'perplex', 'perplex', 'perplex', 'exhaust', 'exhaust', 'exhaust', 'exhaust', 'exhaust', 'beat', 'beat', 'beat', 'beat', 'beat', 'beat', 'perplex', 'perplex', 'perplex', 'perplex', 'perplex', 'perplex', 'perplex', 'perplex', 'perplex', 'perplex', 'perplex', 'perplex', 'perplex', 'perplex', 'perplex', 'perplex', 'exhaust', 'exhaust', 'exhaust', 'exhaust', 'exhaust', 'flex', 'flex', 'flex', 'flex', 'flex', 'crouch', 'crouch', 'crouch', 'crouch', 'better', 'better', 'better', 'better', 'better', 'better', 'better', 'better', 'better', 'adhere', 'adhere', 'adhere', 'adhere', 'adhere', 'adhere', 'bind', 'bind', 'bind', 'bind', 'bind', 'tie_down', 'tie_down', 'tie_down', 'tie_down', 'oblige', 'oblige', 'oblige', 'oblige', 'bind', 'tie', 'tie', 'bind', 'constipate', 'constipate', 'blast', 'blast', 'blast', 'blast', 'blind', 'obstruct', 'obstruct', 'obstruct', 'obstruct', 'obstruct', 'obstruct', 'obstruct', 'waste', 'waste', 'waste', 'blow', 'blow', 'boast', 'boast', 'boast', 'boast', 'boast', 'boast', 'boast', 'boast', 'boast', 'boast', 'blur', 'blur', 'blur', 'bear', 'bear', 'bear', 'bear', 'bear', 'bear', 'hold', 'hold', 'hold', 'hold', 'yield', 'yield', 'yield', 'behave', 'behave', 'behave', 'behave', 'behave', 'behave', 'behave', 'emboss', 'emboss', 'emboss', 'bound', 'bound', 'restrict', 'restrict', 'restrict', 'restrict', 'restrict', 'restrict', 'restrict', 'bounce', 'bounce', 'bounce', 'bounce', 'bounce', 'bounce', 'bounce', 'bounce', 'bounce', 'adhere', 'adhere', 'adhere', 'adhere', 'adhere', 'adhere', 'bind', 'bind', 'bind', 'bind', 'bind', 'tie_down', 'tie_down', 'tie_down', 'tie_down', 'oblige', 'oblige', 'oblige', 'oblige', 'bind', 'tie', 'tie', 'bind', 'constipate', 'constipate']\n",
            "['concentrate', 'concentrate', 'concentrate', 'concentrate', 'concentrate', 'concentrate', 'concentrate', 'interest', 'interest', 'interest', 'interest', 'concentrate', 'concentrate', 'concentrate', 'concentrate', 'concentrate', 'concentrate', 'concentrate', 'interest', 'interest', 'interest', 'interest', 'take', 'take', 'take', 'take', 'take', 'take', 'take', 'take', 'perform', 'perform', 'perform', 'perform', 'broach', 'broach', 'broach', 'broach', 'broach', 'broach', 'come', 'come', 'come', 'accept', 'accept', 'accept', 'accept', 'travel', 'travel', 'travel', 'travel', 'travel', 'travel', 'support', 'support', 'support', 'support', 'support', 'move', 'move', 'develop', 'develop', 'develop', 'develop', 'develop', 'develop', 'develop', 'delegate', 'delegate', 'delegate', 'delegate', 'delegate', 'delegate', 'develop', 'develop', 'develop', 'develop', 'develop', 'develop', 'develop', 'delegate', 'delegate', 'delegate', 'delegate', 'delegate', 'delegate', 'develop', 'develop', 'develop', 'develop', 'develop', 'develop', 'develop', 'delegate', 'delegate', 'delegate', 'delegate', 'delegate', 'delegate', 'move', 'move', 'move', 'move', 'move', 'move', 'move', 'move', 'move', 'move', 'move', 'move', 'move', 'move', 'act', 'act', 'satisfy', 'satisfy', 'satisfy', 'satisfy', 'distribute', 'distribute', 'compel', 'compel', 'compel', 'act', 'act', 'act', 'come', 'come', 'address', 'stimulate', 'stimulate', 'stimulate', 'stimulate', 'stimulate', 'compose', 'compose', 'organize', 'organize', 'organize', 'organize', 'evaluate', 'evaluate', 'think', 'think', 'think', 'think', 'think', 'think', 'think', 'interact', 'interact', 'interact', 'interact', 'unite', 'unite', 'take', 'take', 'take', 'take', 'take', 'dissemble', 'dissemble', 'dissemble', 'dissemble', 'dress', 'dress', 'dress', 'dress', 'dress', 'take', 'take', 'take', 'take', 'take', 'dissemble', 'dissemble', 'dissemble', 'dissemble', 'dress', 'dress', 'dress', 'dress', 'dress', 'declare', 'declare', 'declare', 'declare', 'protective_covering', 'protective_covering', 'protective_covering', 'protective_covering', 'support', 'support', 'position', 'approve', 'approve', 'approve', 'approve', 'approve', 'approve', 'travel', 'bet', 'bet', 'bet', 'bet', 'bet', 'bet', 'bet', 'bet', 'bet', 'bet', 'bet', 'bet', 'copulate', 'copulate', 'copulate', 'copulate', 'copulate', 'copulate', 'copulate', 'copulate', 'copulate', 'copulate', 'copulate', 'copulate', 'copulate', 'copulate', 'copulate', 'copulate', 'copulate', 'copulate', 'copulate', 'copulate', 'copulate', 'copulate', 'copulate', 'copulate', 'copulate', 'expel', 'expel', 'expel', 'control', 'control', 'assumption', 'assumption', 'assumption', 'assumption', 'assumption', 'assumption', 'support', 'support', 'support', 'ester', 'ester', 'compound', 'compound', 'singing_voice', 'singing_voice', 'singing_voice', 'musical_instrument', 'percoid_fish', 'hit', 'recess', 'recess', 'support', 'have', 'produce', 'produce', 'produce', 'produce', 'produce', 'permit', 'permit', 'permit', 'permit', 'permit', 'permit', 'permit', 'permit', 'permit', 'permit', 'permit', 'permit', 'transport', 'make', 'make', 'take', 'take', 'take', 'take', 'include', 'include', 'include', 'include', 'gain', 'gain', 'gain', 'act', 'act', 'act', 'act', 'act', 'act', 'act', 'poetic_rhythm', 'poetic_rhythm', 'poetic_rhythm', 'poetic_rhythm', 'poetic_rhythm', 'get_the_better_of', 'get_the_better_of', 'get_the_better_of', 'get_the_better_of', 'get_the_better_of', 'get_the_better_of', 'strike', 'move', 'move', 'move', 'shape', 'move', 'move', 'agitate', 'agitate', 'move', 'move', 'confuse', 'confuse', 'confuse', 'confuse', 'confuse', 'confuse', 'confuse', 'confuse', 'confuse', 'confuse', 'confuse', 'confuse', 'confuse', 'confuse', 'confuse', 'confuse', 'tire', 'tire', 'tire', 'tire', 'tire', 'move', 'move', 'agitate', 'agitate', 'move', 'move', 'confuse', 'confuse', 'confuse', 'confuse', 'confuse', 'confuse', 'confuse', 'confuse', 'confuse', 'confuse', 'confuse', 'confuse', 'confuse', 'confuse', 'confuse', 'confuse', 'tire', 'tire', 'tire', 'tire', 'tire', 'change_shape', 'change_shape', 'change_shape', 'change_shape', 'change_shape', 'bend', 'bend', 'bend', 'bend', 'change', 'change', 'change', 'change', 'change', 'change_state', 'change_state', 'change_state', 'change_state', 'attach', 'attach', 'attach', 'attach', 'attach', 'attach', 'relate', 'relate', 'relate', 'relate', 'attach', 'restrain', 'restrain', 'restrain', 'restrain', 'relate', 'relate', 'relate', 'relate', 'cover', 'fasten', 'fasten', 'adhere', 'indispose', 'indispose', 'fire', 'fire', 'fire', 'fire', 'change', 'impede', 'impede', 'impede', 'impede', 'impede', 'impede', 'impede', 'use', 'use', 'use', 'send', 'move', 'overstate', 'overstate', 'overstate', 'overstate', 'overstate', 'overstate', 'overstate', 'overstate', 'overstate', 'overstate', 'weaken', 'weaken', 'weaken', 'make', 'make', 'take', 'take', 'take', 'take', 'include', 'include', 'include', 'include', 'gain', 'gain', 'gain', 'act', 'act', 'act', 'act', 'act', 'act', 'act', 'impress', 'impress', 'impress', 'enclose', 'enclose', 'control', 'control', 'control', 'control', 'control', 'control', 'control', 'jump', 'jump', 'jump', 'jump', 'jump', 'jump', 'jump', 'jump', 'jump', 'attach', 'attach', 'attach', 'attach', 'attach', 'attach', 'relate', 'relate', 'relate', 'relate', 'attach', 'restrain', 'restrain', 'restrain', 'restrain', 'relate', 'relate', 'relate', 'relate', 'cover', 'fasten', 'fasten', 'adhere', 'indispose', 'indispose']\n",
            "['drink_in', 'drink_in', 'drink_in', 'drink_in', 'drink_in', 'drink_in', 'drink_in', 'consume', 'consume', 'consume', 'consume', 'drink_in', 'drink_in', 'drink_in', 'drink_in', 'drink_in', 'drink_in', 'drink_in', 'consume', 'consume', 'consume', 'consume', 'face_the_music', 'face_the_music', 'face_the_music', 'face_the_music', 'face_the_music', 'face_the_music', 'face_the_music', 'face_the_music', 'mime', 'mime', 'mime', 'mime', 'discourse', 'discourse', 'discourse', 'discourse', 'discourse', 'discourse', 'approach', 'approach', 'approach', 'take_up', 'take_up', 'take_up', 'take_up', 'close_in', 'close_in', 'close_in', 'close_in', 'close_in', 'close_in', 'carry', 'carry', 'carry', 'carry', 'carry', 'nose', 'nose', 'climb', 'climb', 'climb', 'climb', 'climb', 'climb', 'climb', 'brevet', 'brevet', 'brevet', 'brevet', 'brevet', 'brevet', 'climb', 'climb', 'climb', 'climb', 'climb', 'climb', 'climb', 'brevet', 'brevet', 'brevet', 'brevet', 'brevet', 'brevet', 'climb', 'climb', 'climb', 'climb', 'climb', 'climb', 'climb', 'brevet', 'brevet', 'brevet', 'brevet', 'brevet', 'brevet', 'beat', 'beat', 'beat', 'beat', 'beat', 'beat', 'beat', 'beat', 'beat', 'beat', 'beat', 'beat', 'beat', 'beat', 'spell', 'spell', 'go_a_long_way', 'go_a_long_way', 'go_a_long_way', 'go_a_long_way', 'administer', 'administer', 'execute', 'execute', 'execute', 'confront', 'confront', 'confront', 'get_on', 'get_on', 'hit', 'tempt', 'tempt', 'tempt', 'tempt', 'tempt', 'prearrange', 'prearrange', 'phrase', 'phrase', 'phrase', 'phrase', 'relegate', 'relegate', 'correlate', 'correlate', 'correlate', 'correlate', 'correlate', 'correlate', 'correlate', 'ally', 'ally', 'ally', 'ally', 'walk', 'walk', 'annex', 'annex', 'annex', 'annex', 'annex', 'feint', 'feint', 'feint', 'feint', 'hat', 'hat', 'hat', 'hat', 'hat', 'annex', 'annex', 'annex', 'annex', 'annex', 'feint', 'feint', 'feint', 'feint', 'hat', 'hat', 'hat', 'hat', 'hat', 'contract', 'contract', 'contract', 'contract', 'half_binding', 'half_binding', 'half_binding', 'half_binding', 'cantle', 'cantle', 'fullback', 'champion', 'champion', 'champion', 'champion', 'champion', 'champion', 'back_out', 'ante', 'ante', 'ante', 'ante', 'ante', 'ante', 'ante', 'ante', 'ante', 'ante', 'ante', 'ante', 'fornicate', 'fornicate', 'fornicate', 'fornicate', 'fornicate', 'fornicate', 'fornicate', 'fornicate', 'fornicate', 'fornicate', 'fornicate', 'fornicate', 'fornicate', 'fornicate', 'fornicate', 'fornicate', 'fornicate', 'fornicate', 'fornicate', 'fornicate', 'fornicate', 'fornicate', 'fornicate', 'fornicate', 'fornicate', 'spike', 'spike', 'spike', 'price_floor', 'price_floor', 'meat_and_potatoes', 'meat_and_potatoes', 'meat_and_potatoes', 'meat_and_potatoes', 'meat_and_potatoes', 'meat_and_potatoes', 'brass_monkey', 'brass_monkey', 'brass_monkey', 'adenosine_diphosphate', 'adenosine_diphosphate', 'imidazole', 'imidazole', 'basso_profundo', 'basso_profundo', 'basso_profundo', 'bass_fiddle', 'freshwater_bass', 'switch-hit', 'carrel', 'carrel', 'ball_bearing', 'carry', 'calve', 'calve', 'calve', 'calve', 'calve', 'accept', 'accept', 'accept', 'accept', 'accept', 'accept', 'accept', 'accept', 'accept', 'accept', 'accept', 'accept', 'frogmarch', 'crop', 'crop', 'face_the_music', 'face_the_music', 'face_the_music', 'face_the_music', 'enclose', 'enclose', 'enclose', 'enclose', 'net', 'net', 'net', 'assert', 'assert', 'assert', 'assert', 'assert', 'assert', 'assert', 'catalexis', 'catalexis', 'catalexis', 'catalexis', 'catalexis', 'cheat', 'cheat', 'cheat', 'cheat', 'cheat', 'cheat', 'bastinado', 'flap', 'flap', 'flap', 'forge', 'bate', 'bate', 'cream', 'cream', 'clap', 'clap', 'elude', 'elude', 'elude', 'elude', 'elude', 'elude', 'elude', 'elude', 'elude', 'elude', 'elude', 'elude', 'elude', 'elude', 'elude', 'elude', 'frazzle', 'frazzle', 'frazzle', 'frazzle', 'frazzle', 'bate', 'bate', 'cream', 'cream', 'clap', 'clap', 'elude', 'elude', 'elude', 'elude', 'elude', 'elude', 'elude', 'elude', 'elude', 'elude', 'elude', 'elude', 'elude', 'elude', 'elude', 'elude', 'frazzle', 'frazzle', 'frazzle', 'frazzle', 'frazzle', 'convolve', 'convolve', 'convolve', 'convolve', 'convolve', 'huddle', 'huddle', 'huddle', 'huddle', 'advance', 'advance', 'advance', 'advance', 'advance', 'fructify', 'fructify', 'fructify', 'fructify', 'bind', 'bind', 'bind', 'bind', 'bind', 'bind', 'befriend', 'befriend', 'befriend', 'befriend', 'cement', 'chain_up', 'chain_up', 'chain_up', 'chain_up', 'article', 'article', 'article', 'article', 'rebind', 'band', 'band', 'ligate', 'obstipate', 'obstipate', 'blaze_away', 'blaze_away', 'blaze_away', 'blaze_away', 'abacinate', 'barricade', 'barricade', 'barricade', 'barricade', 'barricade', 'barricade', 'barricade', 'burn', 'burn', 'burn', 'blast', 'whiff', 'gloat', 'gloat', 'gloat', 'gloat', 'gloat', 'gloat', 'gloat', 'gloat', 'gloat', 'gloat', 'obliterate', 'obliterate', 'obliterate', 'crop', 'crop', 'face_the_music', 'face_the_music', 'face_the_music', 'face_the_music', 'enclose', 'enclose', 'enclose', 'enclose', 'net', 'net', 'net', 'assert', 'assert', 'assert', 'assert', 'assert', 'assert', 'assert', 'block', 'block', 'block', 'shore', 'shore', 'baffle', 'baffle', 'baffle', 'baffle', 'baffle', 'baffle', 'baffle', 'carom', 'carom', 'carom', 'carom', 'carom', 'carom', 'carom', 'carom', 'carom', 'bind', 'bind', 'bind', 'bind', 'bind', 'bind', 'befriend', 'befriend', 'befriend', 'befriend', 'cement', 'chain_up', 'chain_up', 'chain_up', 'chain_up', 'article', 'article', 'article', 'article', 'rebind', 'band', 'band', 'ligate', 'obstipate', 'obstipate']\n"
          ]
        }
      ]
    }
  ]
}